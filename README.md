# Transformers Articles and Video
1. [Attention Is All You Need (official paper)](https://arxiv.org/pdf/1706.03762)
2. [Positional Encoding](https://kazemnejad.com/blog/transformer_architecture_positional_encoding/)
3. [Jay Allamar Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
4. [Andrej Karpathy-LLM video]([url](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=588s)
5. [LilLog's Attention](https://lilianweng.github.io/posts/2018-06-24-attention/)
6. [Attention Explained](https://medium.com/data-science/attention-from-alignment-practically-explained-548ef6588aa4)
